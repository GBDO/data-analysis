{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "출처 : https://www.kaggle.com/code/prashant111/logistic-regression-classifier-tutorial\n",
        "\n",
        "## 1. 로지스틱 회귀분석(Logistic Regression | Logit Regression)\n",
        "\n",
        "> 이산 클래스 집합에 대한 예측을 할 때 사용하는 지도 학습 분류 알고리즘이다. 결과도 이산 값으로 출력된다.\n",
        "\n",
        "## 2. 로지스틱 회귀분석 과정\n",
        "<br>\n",
        "### 2-1. 선형 방정식 구현\n",
        "\n",
        "> 예측에 사용되는 독립 변수가 하나일 경우 다음과 같이 일차 방정식으로 모델이 학습됩니다.\n",
        "\t\n",
        "        z = β0 + β1x1\n",
        "\n",
        "> 하나가 아닌 여러 독립 변수를 가지는 경우는 n차 방정식으로 모델이 학습됩니다.\n",
        "\n",
        "         z = β0+ β1x1+ β2x2+……..+ βnxn\n",
        "\n",
        ">  여기서 β0과 β1, βn은 모델의 회귀 계수입니다.  \n",
        "\n",
        "</br>\n",
        "\n",
        "### 2-2. 시그모이드 함수를 통해 확률 값으로 변환( 0~1 사이 범위 )\n",
        "\n",
        "> Z는 어떤 값이든 들어 갈 수 이지만 확률로 표현하기 위해 시그모이드 함수를 이용해서 값의 범위를 0~1로 만듭니다. 시그모이드는 아래의 그래프에서 보이는 것과 같이 양의 무한의 값에서 무한히 1에 가까워지고, 음의 무한의 값에서 0에 가까워지는 모양을 보입니다.\n",
        "\n",
        "### 2-3. 결정 결계 설정 및 분류\n",
        "\n",
        "> 결정 경계( 임계 값 )를 설정하고 그것을 기준으로 시그모이드 함수로 변환된 값을 분류합니다. 보통 0과 1의 중간 값인 0.5가 결정 경계가 됩니다.\n",
        " 아래의 그림은 0.5의 결정 경계 의해 시그모이드 함수를 통해 변환된 값들이 어떻게 분류되는지 보여줍니다. \n",
        "\n",
        "## 3. 로지스틱 회귀의 가정\n",
        "\n",
        "> 로지스틱 회귀 모델을 사용하기 위해서 조건이 있습니다. \n",
        "\n",
        "1. 종속 변수가 이진, 다항 또는 순서형이다.\n",
        "\n",
        "2. 독립 변수가 서로 독립적이다.(높은 상관 관계를 가져서는 안된다.)\n",
        "\n",
        "3. 종속 변수가 서로 독립적이다.\n",
        "\n",
        "4. 독립 변수와 로그 확률은 선형성을 가진다.\n"
      ],
      "metadata": {
        "id": "SnJbUuQ2UxTv"
      }
    }
  ]
}